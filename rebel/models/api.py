from pydantic import BaseModel
from enum import Enum
from typing import Literal, List, Optional, Dict, Any
import json


class RoleEnum(str, Enum):
    """Enumeration for the roles in a conversation, such as in a chat-based model.

    Attributes:
        user (str): Represents a message from the end-user.
        assistant (str): Represents a message from the AI assistant.
        tool (str): Represents the output of a tool or function call.
        system (str): Represents a system-level instruction or context.
    """
    user = 'user'
    assistant = 'assistant'
    tool = 'tool'
    system = 'system'


class Function(BaseModel):
    """Represents a function call with a name and its arguments.

    Attributes:
        name (str): The name of the function that was called.
        arguments (str): A JSON string representing the arguments passed to the function.
    """
    name: str
    arguments: str

    def parse_arguments(self) -> Dict[str, Any]:
        """Parses the JSON string of arguments into a Python dictionary.

        Returns:
            Dict[str, Any]: A dictionary containing the function's arguments.
        """
        return json.loads(self.arguments)


class ToolCall(BaseModel):
    """Represents a request from the model to call a tool (e.g., a function).

    This class handles the standardized structure for a tool call and includes logic
    to initialize from different data patterns.

    Attributes:
        id (str): The unique identifier for the tool call.
        type (Literal['function']): The type of the tool call. Currently defaults to 'function'.
        function (Function): The specific function to be called, including its name and arguments.
    """
    id: str = ''
    type: Literal['function'] = 'function'
    function: Function

    def __init__(self, **data):
        """Initializes a ToolCall, supporting multiple input formats.

        This custom initializer allows creating a ToolCall instance either from the standard
        {'function': {'name': ..., 'arguments': ...}} structure or from a flatter
        {'name': ..., 'input_parameters': ...} structure by converting it internally.

        Args:
            **data: The raw data for creating the ToolCall instance.
        """
        # Handle both patterns in __init__
        if 'name' in data and 'input_parameters' in data and 'function' not in data:
            # New pattern: convert to old pattern
            function = Function(
                name=data.pop('name'),
                arguments=json.dumps(data.pop('input_parameters'))
            )
            data['function'] = function
        
        super().__init__(**data)


class Message(BaseModel):
    """Represents a single message in a conversational chain.

    Attributes:
        role (RoleEnum): The role of the entity that produced the message.
        content (str): The text content of the message.
        tool_calls (Optional[List[ToolCall]]): A list of tool calls requested by the assistant.
        tool_call_id (Optional[str]): The ID of the tool call this message is a response to.
            This is used for messages with the 'tool' role.
    """
    role: RoleEnum
    content: str
    tool_calls: Optional[List[ToolCall]] = None
    tool_call_id: Optional[str] = None


class AssistantInput(BaseModel):
    """Defines the complete input for an assistant or language model.

    This class bundles the conversational history with any API-specific parameters
    needed for the model invocation.

    Attributes:
        messages (List[Message]): The sequence of messages forming the conversation history.
        api_params (Dict[str, Any]): A dictionary of parameters to be passed to the
            model's API, such as temperature or max_tokens.
    """
    messages: List[Message]
    api_params: Dict[str, Any]


class AssistantOutput(BaseModel):
    """Represents the output generated by an assistant after processing an input.

    Attributes:
        output (Optional[str]): The primary text response from the assistant. Defaults to ''.
        tools_called (Optional[List[ToolCall]]): A list of any tools or functions the
            assistant decided to call. Defaults to an empty list.
        context (Optional[List[str]]): Additional context information, such as retrieved
            documents or sources used to generate the response. Defaults to an empty list.
        execution_time (Optional[float]): The time in seconds it took to generate the output.
            This is typically `None` when defining an expected output for a test case.
    """
    output: Optional[str] = ''
    tools_called: Optional[List[ToolCall]] = []
    context: Optional[List[str]] = []
    execution_time: Optional[float] = None # None for expected output
