<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Quick Start &#8212; REBEL 0.2.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=938c9ccc"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Defining Tests" href="defining_tests.html" />
    <link rel="prev" title="Installation" href="installation.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="quick-start">
<span id="id1"></span><h1>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">¶</a></h1>
<p>This guide provides a high-level overview of the REBEL workflow, from defining your evaluation criteria to running a benchmark.</p>
<section id="choose-or-define-your-metrics">
<h2>1. Choose or Define Your Metrics<a class="headerlink" href="#choose-or-define-your-metrics" title="Link to this heading">¶</a></h2>
<p>The first step in any evaluation is deciding <em>how</em> to measure performance. REBEL allows you to use built-in metrics or easily create your own.</p>
<p>For a comprehensive guide on all metric types, see the <a class="reference internal" href="metrics.html#metrics"><span class="std std-ref">Metrics</span></a> page.</p>
<p>Here is an example of a simple custom metric that checks if the assistant correctly counts the occurrences of a specific letter in its output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rebel.models</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Metric</span><span class="p">,</span>
    <span class="n">AssistantInput</span><span class="p">,</span>
    <span class="n">AssistantOutput</span><span class="p">,</span>
    <span class="n">EvaluationResult</span><span class="p">,</span>
    <span class="n">EvaluationVerdict</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LettersCalculationCorrectness</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="n">letter</span><span class="p">:</span> <span class="nb">str</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">measure</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">AssistantInput</span><span class="p">,</span>
        <span class="n">expected</span><span class="p">:</span> <span class="n">AssistantOutput</span><span class="p">,</span>
        <span class="n">actual</span><span class="p">:</span> <span class="n">AssistantOutput</span>
    <span class="p">):</span>
        <span class="n">user_message</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">messages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
        <span class="n">expected_letter_count</span> <span class="o">=</span> <span class="n">user_message</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">letter</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">actual_letter_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">actual</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">EvaluationResult</span><span class="p">(</span>
                <span class="n">score</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">verdict</span><span class="o">=</span><span class="n">EvaluationVerdict</span><span class="o">.</span><span class="n">FAILED</span><span class="p">,</span>
                <span class="n">reason</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Invalid answer format, expected int, got &quot;</span><span class="si">{</span><span class="n">actual</span><span class="o">.</span><span class="n">output</span><span class="si">}</span><span class="s1">&quot;&#39;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">actual_letter_count</span> <span class="o">!=</span> <span class="n">expected_letter_count</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">EvaluationResult</span><span class="p">(</span>
                <span class="n">score</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">verdict</span><span class="o">=</span><span class="n">EvaluationVerdict</span><span class="o">.</span><span class="n">FAILED</span><span class="p">,</span>
                <span class="n">reason</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Incorrect result, expected </span><span class="si">{</span><span class="n">expected_letter_count</span><span class="si">}</span><span class="s1">, got </span><span class="si">{</span><span class="n">actual_letter_count</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">EvaluationResult</span><span class="p">(</span>
            <span class="n">score</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">verdict</span><span class="o">=</span><span class="n">EvaluationVerdict</span><span class="o">.</span><span class="n">PASSED</span><span class="p">,</span>
            <span class="n">reason</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Good job :)&#39;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;Letters Calculation Correctness&#39;</span>
</pre></div>
</div>
</section>
<section id="define-your-tests">
<h2>2. Define Your Tests<a class="headerlink" href="#define-your-tests" title="Link to this heading">¶</a></h2>
<p>Once you have your metric, you can define test cases using the <code class="docutils literal notranslate"><span class="pre">&#64;test_case</span></code> decorator. This example uses the <cite>LetterCountMetric</cite> we defined above to evaluate the test.</p>
<p>For more details on creating tests, see the <a class="reference internal" href="defining_tests.html#defining-tests"><span class="std std-ref">Defining Tests</span></a> guide.</p>
</section>
<section id="run-your-benchmarks">
<h2>3. Run Your Benchmarks<a class="headerlink" href="#run-your-benchmarks" title="Link to this heading">¶</a></h2>
<p>Execute your tests using the <code class="docutils literal notranslate"><span class="pre">rebel</span></code> command from your terminal. You must provide a directory for your tests, a folder for the results, and a method for configuring the API client.</p>
<p>There are two primary ways to configure the client:</p>
<p><strong>Option 1: Using a Configuration File (Recommended)</strong></p>
<p>This is the simplest method. Create a JSON file with your API credentials and pass its path to the <code class="docutils literal notranslate"><span class="pre">--api-config</span></code> argument. This will use the built-in <code class="docutils literal notranslate"><span class="pre">OpenAIAPIClient</span></code>.</p>
<p>For example, you can create a file named <cite>model_config.json</cite> with the following content. Be sure to replace <cite>“YOUR_API_KEY_HERE”</cite> with your actual API key.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;google/gemini-2.5-flash&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;base_url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://openrouter.ai/api/v1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;api_key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YOUR_API_KEY_HERE&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>You can then run the benchmark by referencing this file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rebel<span class="w"> </span>--test-dir<span class="w"> </span>tests/<span class="w"> </span>--output-folder<span class="w"> </span>results/<span class="w"> </span>--api-config<span class="w"> </span>model_config.json
</pre></div>
</div>
<p><strong>Option 2: Using a Custom API Client</strong></p>
<p>For advanced use cases, such as integrating with a different API provider, you can create your own client class. Your custom class must inherit from <a class="reference internal" href="api.html#rebel.collector.api_client.APIClient" title="rebel.collector.api_client.APIClient"><code class="xref py py-class docutils literal notranslate"><span class="pre">rebel.collector.api_client.APIClient</span></code></a> and implement the <code class="docutils literal notranslate"><span class="pre">request</span></code> method.</p>
<p>Here is a basic template for a custom client:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># my_package/my_client.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rebel.collector</span><span class="w"> </span><span class="kn">import</span> <span class="n">APIClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rebel.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssistantInput</span><span class="p">,</span> <span class="n">AssistantOutput</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MyAPIClient</span><span class="p">(</span><span class="n">APIClient</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">retries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retries</span> <span class="o">=</span> <span class="n">retries</span>
        <span class="c1"># ... your client initialization logic ...</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">request</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">AssistantInput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AssistantOutput</span><span class="p">:</span>
        <span class="c1"># ... your logic to call the external API ...</span>
        <span class="c1"># ... format the response into an AssistantOutput object ...</span>
        <span class="k">return</span> <span class="n">AssistantOutput</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="s2">&quot;Response from custom client.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then run the benchmark with your custom client. The arguments in <cite>–api-client-args</cite> will be passed to your class’s constructor.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rebel<span class="w"> </span>--test-dir<span class="w"> </span>tests/<span class="w"> </span>--output-folder<span class="w"> </span>results/<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--api-client-module<span class="w"> </span>my_package.my_client<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--api-client-class<span class="w"> </span>MyAPIClient<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--api-client-args<span class="w"> </span><span class="s1">&#39;{&quot;api_key&quot;: &quot;your-secret-key&quot;, &quot;retries&quot;: 3}&#39;</span>
</pre></div>
</div>
<section id="command-line-arguments">
<h3>Command-Line Arguments<a class="headerlink" href="#command-line-arguments" title="Link to this heading">¶</a></h3>
<p>Here is a complete list of all available CLI arguments.</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">REBEL CLI Arguments</span><a class="headerlink" href="#id2" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 60.0%" />
<col style="width: 10.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--test-dir</span></code></p></td>
<td><p>Directory containing the test files to be discovered.</p></td>
<td><p><strong>Yes</strong></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--output-folder</span></code></p></td>
<td><p>Directory where the test results will be saved.</p></td>
<td><p><strong>Yes</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--api-config</span></code></p></td>
<td><p>Path to the API configuration JSON file. Used if a custom client is not specified.</p></td>
<td><p>Conditional</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--api-client-module</span></code></p></td>
<td><p>The Python module path for a custom API client (e.g., ‘my_package.my_client’). Takes priority over <code class="docutils literal notranslate"><span class="pre">--api-config</span></code>.</p></td>
<td><p>Conditional</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--api-client-class</span></code></p></td>
<td><p>The class name of your custom API client.</p></td>
<td><p>Conditional</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--api-client-args</span></code></p></td>
<td><p>A JSON string of keyword arguments to pass to your custom client’s constructor.</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--keyword</span></code></p></td>
<td><p>Filter tests to run only those whose names contain this keyword.</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--tags</span></code></p></td>
<td><p>Filter tests to run only those that have the specified tag(s).</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--exclude-tags</span></code></p></td>
<td><p>Exclude any tests that have the specified tag(s).</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--num-workers-api</span></code></p></td>
<td><p>The number of parallel worker threads for making API calls. (Default: 4)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--num-workers-eval</span></code></p></td>
<td><p>The number of parallel worker threads for running evaluations. (Default: 4)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="analyze-the-results">
<h2>4. Analyze the Results<a class="headerlink" href="#analyze-the-results" title="Link to this heading">¶</a></h2>
<p>REBEL generates a detailed JSON report in your specified output directory, organized by model and timestamp. This allows for easy comparison and historical analysis.</p>
<p>See the <a class="reference internal" href="results.html#results"><span class="std std-ref">Results</span></a> guide for more information on the output format.</p>
<section id="next-steps">
<h3>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">¶</a></h3>
<p>For a complete, end-to-end implementation with multiple models and advanced metrics, check out our detailed walkthrough: <a class="reference internal" href="example_openrouter.html#example-openrouter"><span class="std std-ref">Example: Benchmarking with OpenRouter</span></a>.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">REBEL</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#choose-or-define-your-metrics">1. Choose or Define Your Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#define-your-tests">2. Define Your Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-your-benchmarks">3. Run Your Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#analyze-the-results">4. Analyze the Results</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="defining_tests.html">Defining Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepeval_integration.html">DeepEval Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="results.html">Results</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example_openrouter.html">Example: Benchmarking with OpenRouter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="installation.html" title="previous chapter">Installation</a></li>
      <li>Next: <a href="defining_tests.html" title="next chapter">Defining Tests</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, TensorSearch.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/quick_start.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>